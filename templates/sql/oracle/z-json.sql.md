###### Oracle PL/SQL
### JSON
#### (with Ansible Tower — build extravars, ingest CLOB, parse, persist (Oracle 19c))
End-to-end patterns you can paste into your repo: generate outbound JSON for Ansible Tower/AWX, capture inbound JSON payloads (array or object), and materialize fields back into columns.

---

## 0) Demo schema (JSON column + constraints + simple index)
```sql
-- Requests initiated to Ansible; response JSON lands here
CREATE TABLE tower_jobs (
  job_id        NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  workflow_name VARCHAR2(128)  NOT NULL,
  account_id    NUMBER         NOT NULL,
  extravars     CLOB           CHECK (extravars IS JSON),   -- outbound JSON
  result_json   CLOB           CHECK (result_json IS JSON), -- inbound JSON
  status        VARCHAR2(30),
  started_at    TIMESTAMP,
  finished_at   TIMESTAMP,
  rc            NUMBER,         -- return code, if provided
  msg           VARCHAR2(4000)  -- short message
);

-- Frequent lookups: function-based index on scalar JSON keys (fast & simple)
CREATE INDEX ix_tower_jobs_status
  ON tower_jobs ( JSON_VALUE(result_json, '$.status' RETURNING VARCHAR2(30)) );

-- (Optional) a JSON Search Index (richer, space-heavier)
-- CREATE SEARCH INDEX jsx_tower_jobs ON tower_jobs(result_json) FOR JSON;
````

---

## 1) Build **Ansible extravars** JSON (hash) — two idioms

### 1a) Pure SQL builder (`JSON_OBJECT` / `JSON_ARRAYAGG`)

```sql
DECLARE
  v_extravars CLOB;
BEGIN
  SELECT JSON_OBJECT(
           'account_id'    VALUE :account_id,
           'request_id'    VALUE SYS_GUID(),
           'flags'         VALUE JSON_OBJECT('dry_run' VALUE :dry_run, 'verbose' VALUE 1),
           'packages'      VALUE (SELECT JSON_ARRAYAGG(p.pkg ORDER BY p.pkg)
                                  FROM (SELECT 'git' pkg FROM dual UNION ALL
                                        SELECT 'curl'    FROM dual) p),
           'metadata'      VALUE JSON_OBJECT('requested_by' VALUE :user, 'source' VALUE 'APEX')
         RETURNING CLOB)
    INTO v_extravars
  FROM dual;

  INSERT INTO tower_jobs(workflow_name, account_id, extravars, status, started_at)
  VALUES (:wf_name, :account_id, v_extravars, 'QUEUED', SYSTIMESTAMP);
END;
/
```

### 1b) PL/SQL object API (`JSON_OBJECT_T` / `JSON_ARRAY_T`)

```sql
DECLARE
  j  JSON_OBJECT_T := JSON_OBJECT_T();
  pk JSON_ARRAY_T  := JSON_ARRAY_T();
BEGIN
  pk.append('git'); pk.append('curl');

  j.put('account_id',   :account_id);
  j.put('request_id',   SYS_GUID());
  j.put('flags',        JSON_OBJECT_T('{"dry_run":false,"verbose":1}'));
  j.put('packages',     pk);
  j.put('metadata',     JSON_OBJECT_T('{"requested_by":"'||:user||'","source":"APEX"}'));

  INSERT INTO tower_jobs(workflow_name, account_id, extravars, status, started_at)
  VALUES (:wf_name, :account_id, j.stringify, 'QUEUED', SYSTIMESTAMP);
END;
/
```

> Tip: Pretty output (for logs) — `SELECT JSON_SERIALIZE(:clob RETURNING CLOB PRETTY) FROM dual;`

---

## 2) Receive **inbound JSON** from Ansible (array **or** object) and store to CLOB

```sql
-- Simulate inbound webhook body as CLOB bind :payload
DECLARE
  v_job_id NUMBER := :job_id;
BEGIN
  UPDATE tower_jobs
  SET    result_json = :payload,        -- raw JSON body
         finished_at = SYSTIMESTAMP,
         status      = 'RECEIVED'
  WHERE  job_id = v_job_id;
END;
/
```

---

## 3) Normalize unknown JSON shape (array vs object) and parse

Sometimes Ansible replies with a top-level **object**:

```json
{"status":"successful","rc":0,"msg":"ok","artifacts":{"host":"srv1","facts":{"os":"rhel"}}}
```

…other times with a top-level **array** of results:

```json
[{"host":"srv1","rc":0,"status":"ok"},{"host":"srv2","rc":1,"status":"failed"}]
```

### 3a) A helper function: coerce to an **object** with a stable wrapper

```sql
CREATE OR REPLACE FUNCTION normalize_json_obj(p_json IN CLOB)
  RETURN JSON_OBJECT_T
IS
  e JSON_ELEMENT_T := JSON_ELEMENT_T.parse(p_json);
BEGIN
  IF e.is_object THEN
    RETURN TREAT(e AS JSON_OBJECT_T);
  ELSIF e.is_array THEN
    -- Wrap array as an object: { "items": [ ... ], "count": N }
    DECLARE
      a   JSON_ARRAY_T  := TREAT(e AS JSON_ARRAY_T);
      out JSON_OBJECT_T := JSON_OBJECT_T();
    BEGIN
      out.put('items', a);
      out.put('count', a.get_size);
      RETURN out;
    END;
  ELSE
    -- Fallback: wrap scalar
    DECLARE out JSON_OBJECT_T := JSON_OBJECT_T(); BEGIN out.put('value', e); RETURN out; END;
  END IF;
END;
/
```

### 3b) Use the helper to extract key fields and persist to columns

```sql
DECLARE
  v_obj   JSON_OBJECT_T;
  v_rc    NUMBER;
  v_stat  VARCHAR2(30);
  v_msg   VARCHAR2(4000);
BEGIN
  SELECT normalize_json_obj(result_json) INTO v_obj
  FROM   tower_jobs
  WHERE  job_id = :job_id
  FOR UPDATE;

  -- Try the common keys first (object reply)
  IF v_obj.has('rc') THEN v_rc := v_obj.get_Number('rc'); END IF;
  IF v_obj.has('status') THEN v_stat := v_obj.get_String('status'); END IF;
  IF v_obj.has('msg') THEN v_msg := v_obj.get_String('msg'); END IF;

  -- If it was an array, we wrapped it as { items: [...], count: N }.
  -- Example: derive aggregate status from items[*].status
  IF v_stat IS NULL AND v_obj.has('items') THEN
    DECLARE
      a     JSON_ARRAY_T := v_obj.get_Array('items');
      ok    PLS_INTEGER := 0;
      fail  PLS_INTEGER := 0;
      i     PLS_INTEGER;
    BEGIN
      FOR i IN 0 .. a.get_size-1 LOOP
        DECLARE r JSON_OBJECT_T := TREAT(a.get(i) AS JSON_OBJECT_T); BEGIN
          IF r.has('status') AND LOWER(r.get_String('status')) IN ('ok','successful') THEN ok := ok+1;
          ELSIF r.has('status') THEN fail := fail+1;
          END IF;
        END;
      END LOOP;
      v_stat := CASE WHEN fail=0 THEN 'successful' WHEN ok=0 THEN 'failed' ELSE 'partial' END;
      v_rc   := CASE WHEN fail=0 THEN 0 ELSE 1 END;
      v_msg  := 'items='||a.get_size||' ok='||ok||' fail='||fail;
    END;
  END IF;

  UPDATE tower_jobs
  SET    status = v_stat,
         rc     = v_rc,
         msg    = v_msg
  WHERE  job_id = :job_id;

  COMMIT;
END;
/
```

---

## 4) SQL-first projection with `JSON_TABLE` (fast for regular shapes)

### 4a) Project common response fields from `result_json` to columns

```sql
UPDATE tower_jobs t
SET   (status, rc, msg) = (
  SELECT jt.status, jt.rc, jt.msg
  FROM   JSON_TABLE(t.result_json, '$'
           COLUMNS (
             status  VARCHAR2(30)  PATH '$.status' DEFAULT 'unknown' ON ERROR,
             rc      NUMBER        PATH '$.rc'     DEFAULT 1         ON ERROR,
             msg     VARCHAR2(4000) PATH '$.msg'
           )
         ) jt
)
WHERE t.job_id = :job_id;
```

### 4b) When top is an **array**: explode with `NESTED PATH`

```sql
-- Example: insert item rows into a detail table for analytics
CREATE TABLE tower_job_items (
  job_id  NUMBER NOT NULL,
  idx     NUMBER NOT NULL,
  host    VARCHAR2(128),
  status  VARCHAR2(30),
  rc      NUMBER,
  CONSTRAINT tji_pk PRIMARY KEY (job_id, idx)
);

INSERT /*+ APPEND */ INTO tower_job_items (job_id, idx, host, status, rc)
SELECT t.job_id, jt.idx, jt.host, jt.status, jt.rc
FROM   tower_jobs t,
       JSON_TABLE(t.result_json, '$'
         COLUMNS (
           NESTED PATH '$[*]' COLUMNS (
             idx   FOR ORDINALITY,
             host  VARCHAR2(128) PATH '$.host',
             status VARCHAR2(30) PATH '$.status',
             rc     NUMBER       PATH '$.rc'
           )
         )
       ) jt
WHERE  t.job_id = :job_id;
```

---

## 5) Mutate/patch JSON you stored (merge new keys, keep old)

```sql
-- Add/override a few keys in-place
UPDATE tower_jobs
SET    result_json = JSON_MERGEPATCH(result_json, '{"note":"archived","ttl":86400}')
WHERE  job_id = :job_id;
```

---

## 6) Handy utilities (19c+)

### 6a) Pretty print for logs

```sql
SELECT JSON_SERIALIZE(result_json RETURNING CLOB PRETTY) AS pretty
FROM   tower_jobs
WHERE  job_id = :job_id;
```

### 6b) Validate before write (raises on bad JSON)

```sql
DECLARE
  e JSON_ELEMENT_T := JSON_ELEMENT_T.parse(:payload); -- will raise on invalid JSON
BEGIN
  UPDATE tower_jobs SET result_json = e.to_string WHERE job_id = :job_id;
END;
/
```

### 6c) Quick scalar extraction with defaults

```sql
SELECT JSON_VALUE(result_json, '$.artifacts.facts.os' RETURNING VARCHAR2(30)
                   DEFAULT 'unknown' ON ERROR)
FROM   tower_jobs
WHERE  job_id = :job_id;
```

### 6d) Upsert columns from JSON payload (MERGE + JSON_TABLE)

```sql
MERGE INTO tower_jobs d
USING (
  SELECT :job_id job_id, jt.status, jt.rc, jt.msg
  FROM   JSON_TABLE(:payload, '$'
         COLUMNS (
           status  VARCHAR2(30)  PATH '$.status' DEFAULT 'unknown' ON ERROR,
           rc      NUMBER        PATH '$.rc'     DEFAULT 1         ON ERROR,
           msg     VARCHAR2(4000) PATH '$.msg'
         )) jt
) s
ON (d.job_id = s.job_id)
WHEN MATCHED THEN
  UPDATE SET d.status = s.status, d.rc = s.rc, d.msg = s.msg
WHEN NOT MATCHED THEN
  INSERT (job_id, workflow_name, account_id, result_json, status, rc, msg, started_at)
  VALUES (s.job_id, 'unknown', -1, :payload, s.status, s.rc, s.msg, SYSTIMESTAMP);
```

---

## 7) Operational tips

* Use **CLOB CHECK (… IS JSON)** for integrity; combine with function-based indexes on frequently filtered keys.
* Prefer **`JSON_TABLE`** for repeatable shapes (fast, set-based); prefer **`JSON_OBJECT_T/ARRAY_T`** for irregular logic in PL/SQL.
* Normalize mixed array/object payloads by **wrapping arrays** under a stable key (e.g., `"items"`), then aggregate.
* Keep raw JSON **as-is** in `result_json` for auditability; project only what you need to columns.
* For big payloads, watch **PGA/TEMP** usage when materializing large arrays; stream with `JSON_TABLE` where possible.

```yaml
---
id: sql/oracle/plsql/json-ansible-extravars-19c
lang: sql
platform: oracle
scope: plsql
since: "v0.5"
tested_on: "Oracle 19c"
tags: [plsql, json, json_object_t, json_array_t, json_table, json_value, json_mergepatch, clob, ansible]
description: "Build Ansible Tower/AWX extravars JSON; receive inbound JSON (array or object), store in CLOB, and parse to columns. Includes 19c JSON tools: JSON_OBJECT_T/ARRAY_T, JSON_VALUE/JSON_QUERY, JSON_TABLE, JSON_MERGEPATCH, JSON_SERIALIZE, indexing/validation."
---
```